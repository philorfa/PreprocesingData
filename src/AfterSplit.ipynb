{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No metadata found in c:\\users\\user\\anaconda3\\lib\\site-packages\n",
      "WARNING: No metadata found in c:\\users\\user\\anaconda3\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.22.2.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No metadata found in c:\\users\\user\\anaconda3\\lib\\site-packages\n",
      "WARNING: No metadata found in c:\\users\\user\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "#ΤΟ ΘΕΛΩ ΠΑΝΤΟΤΕ\n",
    "! pip install -U scikit-learn\n",
    "#ΤΟ ΘΕΛΩ ΓΙΑ ΝΑ ΚΑΝΩ IMBALANCE ΤΟ DATASET ΜΟΥ\n",
    "! pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ΧΡΗΣΙΜΑ ΕΡΓΑΛΕΙΑ ΠΟΥ ΑΡΓΑ Η ΓΡΗΓΟΡΑ ΘΑ ΤΑ ΤΑ ΧΡΕΙΑΣΤΕΙΣ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#ΧΡΗΣΙΜΟ ΓΙΑ ΝΑ ΠΑΡΕΙΣ ΓΡΑΦΙΚΕΣ ΠΑΡΑΣΤΑΣΕΙΣ\n",
    "#import seaborn as sns\n",
    "\n",
    "#ΕΡΓΑΛΕΙΑ ΓΙΑ ΝΑ ΚΑΝΕΙς IMPUTE TO DATASET ΣΟΥ ΔΗΛΑΔΗ ΝΑ ΓΕΜΊΣΕΙΣ ΜΕ ΤΙΜΕΣ ΤΑ NaN ΚΕΛΙΑ - ΛΕΙΤΟΥΡΓΕΙ ΓΙΑ ΑΡΙΘΜΗΤΙΚΕς ΤΙΜΕΣ\n",
    "#from sklearn.impute import SimpleImputer \n",
    "#from sklearn.experimental import enable_iterative_imputer\n",
    "#from sklearn.impute import IterativeImputer\n",
    "\n",
    "#ΓΙΑ ΝΑ ΚΑΝΕΙΣ LABEL ENCODER\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#ΟΤΑΝ ΘΕΛΕΙΣ ΝΑ ΚΑΝΕΙΣ SPLIT ΤΟ DATASET ΣΟΥ ΣΕ TRAIN-TEST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ΓΙΑ ΜΕΙΩΣΗ ΔΙΑΣΤΑΤΙΚΟΤΗΤΑΣ\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#ΕΡΓΑΛΕΙΑ ΓΙΑ ΝΑ ΠΡΑΓΜΑΤΟΠΟΙΗΣΩ ΙΜΒΑLANCE - OVERSAMPLING - UNDERSAMPLING\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE #ΠΡΟΚΑΛΕΙ ΘΕΜΑΤΑ ΟΤΑΝ ΕΧΟΥΜΕ ΤΕΡΑΣΤΙΕΣ ΔΙΑΦΟΡΕΣ , ΧΡΗΣΙΜΟΠΟΙΕΙ KNN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>3_b'RSTO'</th>\n",
       "      <th>3_b'RSTOS0'</th>\n",
       "      <th>3_b'RSTR'</th>\n",
       "      <th>3_b'S0'</th>\n",
       "      <th>3_b'S1'</th>\n",
       "      <th>3_b'S2'</th>\n",
       "      <th>3_b'S3'</th>\n",
       "      <th>3_b'SF'</th>\n",
       "      <th>3_b'SH'</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    4     5  6  7  8  9 10 11 12  ... 3_b'RSTO' 3_b'RSTOS0' 3_b'RSTR'  \\\n",
       "0  0  181  5450  0  0  0  0  0  1  0  ...         0           0         0   \n",
       "1  0  239   486  0  0  0  0  0  1  0  ...         0           0         0   \n",
       "2  0  235  1337  0  0  0  0  0  1  0  ...         0           0         0   \n",
       "3  0  219  1337  0  0  0  0  0  1  0  ...         0           0         0   \n",
       "4  0  217  2032  0  0  0  0  0  1  0  ...         0           0         0   \n",
       "\n",
       "  3_b'S0' 3_b'S1' 3_b'S2' 3_b'S3' 3_b'SF' 3_b'SH' target  \n",
       "0       0       0       0       0       1       0     11  \n",
       "1       0       0       0       0       1       0     11  \n",
       "2       0       0       0       0       1       0     11  \n",
       "3       0       0       0       0       1       0     11  \n",
       "4       0       0       0       0       1       0     11  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "fetch=fetch_kddcup99()\n",
    "fetch_data=fetch.data\n",
    "fetch_target=fetch.target\n",
    "fetch_Descr=fetch.DESCR\n",
    "fetch_data=pd.DataFrame(data=fetch_data)\n",
    "fetch_target=pd.DataFrame(data=fetch_target,columns=['target'])\n",
    "fetch_data=pd.concat([fetch_data, fetch_target], axis=1)\n",
    "#ONE HOT ENCODING ΓΙΑ ΤΙΣ ΣΤΗΛΕΣ ΠΟΥ ΒΛΕΠΟΥΜΕ ΟΤΙ ΜΑΣ ΕΝΟΧΛΟΥΝ\n",
    "fetch_data=pd.get_dummies(fetch_data,columns=[1,2,3])\n",
    "\n",
    "#ΤΟΠΟΘΕΤΟΥΜΕ ΤΗΝ ΣΤΗΛΗ Τarget ΣΤΟ ΤΕΛΟΣ ΓΙΑΤΙ ΜΑΣ ΕΞΥΠΗΡΕΤΕΙ\n",
    "cols = list(fetch_data.columns.values) \n",
    "cols.pop(cols.index('target')) \n",
    "fetch_data = fetch_data[cols+['target']]\n",
    "\n",
    "#LABEL ENCODING ΓΙΑ ΤΟ Target\n",
    "labelencoder = LabelEncoder()\n",
    "fetch_data.target= labelencoder.fit_transform(fetch_data.target)\n",
    "fetch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εχοντας ολοκληρώσει την BeforeSplit διαδικασία πλεον χωριζουμε το DataSet μας σε train - test και εφαρμόζουμε ορισμένες τεχνικές για βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494021, 119)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_features_df=fetch_data.iloc[:,:118]\n",
    "fetch_labels_df=fetch_data.iloc[:,[118]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_train, fetch_test, fetch_train_labels, fetch_test_labels = train_test_split(fetch_features_df, fetch_labels_df, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "Η κανονικοποίηση των χαρακτηριστικών μπορεί να γίνει με 2 βασικούς τρόπους, γνωστούς και από τη στατιστική. Με την διαίρεση με τη διαφορά μεγίστου-ελαχίστου (feature scaling) οπότε οι τιμές όλων των χαρακτηριστικών κλιμακώνονται γραμμικά στο διάστημα [0,1] ή με το z-score (ή standard score) του κάθε χαρακτηριστικού (standardization), που κάνει το χαρακτηριστικό να έχει μέση τιμή μηδέν και διακύμανση μονάδα, σαν την κανονική κατανομή. \n",
    "\n",
    "Η μετατροπή μεγίστου ελαχίστου γίνεται με τον τύπο $$X' = {{X - X_{min}} \\over {X_{max} - X_{min}}}$$Η μετατροπή σε standard score γίνεται με τον τύπο: $$z = {{X- \\mu }\\over \\sigma}$$ όπου: $μ$ είναι η μέση τιμή του χαρακτηριστικού και $σ$ η απόκλιση. Στην πράξη δεν μας ενδιαφέρει αν η πραγματική κατανομή των χαρακτηριστικών είναι κανονική, απλά αφαιρούμε τη μέση τιμή και διαιρούμε με την απόκλιση για να έχουν τα χαρακτηριστικά της.\n",
    "\n",
    "H μετατροπή σε standard score είναι απαραίτητη σε πολλούς ταξινομητές για να συμπεριφερθούν σωστά. Επίσης είναι πιο ανθεκτική από την min max σε τιμές outliers δηλαδή σποραδικές τιμές που είναι πολύ μακριά απο τη μέση τιμή και τις υπόλοιπες τιμές του χαρακτηριστικού (η min max θα συμπιέσει τις περισσότερες τιμές σε ένα μικρό διάστημα)\n",
    "\n",
    "Από την άλλη η κλιμάκωση σε [0,1] είναι λιγότερο ευαίσθητη σε πολυ μικρές αποκλίσεις και επίσης σε αραιά (sparse) διανύσματα χαρακτηριστικών (δηλαδή με πολλές μηδενικες τιμές) η εφαρμογή της διατηρεί τα μηδέν, κάτι που μπορεί να είναι καθοριστικό για την ταχύτητα εκπαίδευσης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALED STANDARD ΓΙΑ ΟΛΕΣ ΤΙΣ ΠΑΡΑΜΕΤΡΟΥΣ : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "def scaled_Standard(train,test):\n",
    "    cols1=train.columns\n",
    "    cols2=test.columns\n",
    "    scaler = preprocessing.StandardScaler().fit(train)\n",
    "    train_scaled = scaler.transform(train)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    train_scaled=pd.DataFrame(data=train_scaled,columns=cols1)\n",
    "    test_scaled=pd.DataFrame(data=test_scaled,columns=cols2)\n",
    "    return train_scaled,test_scaled\n",
    "\n",
    "#Min Max ΓΙΑ ΟΛΕΣ ΤΙΣ ΠΑΡΑΜΕΤΡΟΥΣ : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "def min_max(train,test):\n",
    "    cols1=train.columns\n",
    "    cols2=test.columns\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    train_scaled = min_max_scaler.fit_transform(train)\n",
    "    test_scaled = min_max_scaler.transform(test)\n",
    "    train_scaled=pd.DataFrame(data=train_scaled,columns=cols1)\n",
    "    test_scaled=pd.DataFrame(data=test_scaled,columns=cols2)\n",
    "    return train_scaled,test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Threshold\n",
    "\n",
    "!! προσοχή όταν χρησιμοποιηθεί με one hot encoder [0,1] μπορεί να σβήσει αρκετά χαρακτηριστικά αν το threshold ξεπεράσει ένα όριο !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ΚΟΒΕΙ ΟΣΑ ΧΑΡΑΚΤΗΡΙΣΤΙΚΑ ΕΧΟΥΝ ΔΙΑΚΥΜΑΝΣΗ ΠΑΝΩ ΑΠΟ ΤΟ ΔΟΘΕΝ ΟΡΙΟ \n",
    "def variance(train,test,thresh):\n",
    "    cols1=train.columns\n",
    "    cols2=test.columns\n",
    "    variance_thresh = VarianceThreshold(thresh)\n",
    "    x_train = variance_thresh.fit_transform(train)\n",
    "    x_test = variance_thresh.transform(test)\n",
    "    x_train=pd.DataFrame(data=x_train,columns=cols1)\n",
    "    x_test=pd.DataFrame(data=x_test,columns=cols2)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMBALANCE YOUR DATA :\n",
    "\n",
    " * Πρώτα βλέπεις πόσες μεταβλητές έχεις --> 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_train_labels.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Μετά βλέπεις τις τιμές την συχνότητα εμφάνισης τους "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max variable= 18 with frequency= 224652\n",
      "Min variable= 12 with frequency= 2\n",
      "ratio= 0.0008902658333778467\n"
     ]
    }
   ],
   "source": [
    "print('Max variable=',fetch_train_labels['target'].value_counts().idxmax(),'with frequency=',fetch_train_labels['target'].value_counts().max())\n",
    "print('Min variable=',fetch_train_labels['target'].value_counts().idxmin(),'with frequency=',fetch_train_labels['target'].value_counts().min())\n",
    "print('ratio=',fetch_train_labels['target'].value_counts().min()*100/fetch_train_labels['target'].value_counts().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>224652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>85703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>77850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target\n",
       "18  224652\n",
       "9    85703\n",
       "11   77850\n",
       "0     1759\n",
       "17    1282\n",
       "5      989\n",
       "15     853\n",
       "21     820\n",
       "20     775\n",
       "14     204\n",
       "10     185\n",
       "3       42\n",
       "1       25\n",
       "6       18\n",
       "22      18\n",
       "4       10\n",
       "7        7\n",
       "8        7\n",
       "2        5\n",
       "13       4\n",
       "16       4\n",
       "12       2\n",
       "19       2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_train_labels.apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Αν έχεις ένα ratio <40% καλό θα ήταν να εξισορροπήσεις το dataset σου , το OverSample ανεβάζει τη συχνότητα των μικρών στα πλαίσια των μεγαλύτερων , το UnderSample ρίχνει τη συχνότητα των μεγάλων στα πλάισια των μικρών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "#SMOTE synthesises new minority instances between existing (real) minority instances\n",
    "#Finding the k-nearest-neighbors for minority class observations (finding similar observations)\n",
    "def smoteoversampler(train,train_labels):\n",
    "    cols1=train.columns\n",
    "    cols2=train_labels.columns\n",
    "    sm = SMOTE()\n",
    "    x_train_res, y_train_res = sm.fit_sample(train, train_labels)\n",
    "    x_train_res=pd.DataFrame(data=x_train_res,columns=cols1)\n",
    "    y_train_res=pd.DataFrame(data=y_train_res,columns=cols2)\n",
    "    return x_train_res, y_train_res\n",
    "\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html\n",
    "#ΠΡΟΣΕΧΕ ΓΙΑ OVERFITTING\n",
    "#Randomly duplicate examples in the minority class.\n",
    "def randomoversampler(train,train_labels):\n",
    "    cols1=train.columns\n",
    "    cols2=train_labels.columns\n",
    "    ros = RandomOverSampler()\n",
    "    X_ros, y_ros = ros.fit_sample(train, train_labels)\n",
    "    X_ros=pd.DataFrame(data=X_ros,columns=cols1)\n",
    "    y_ros=pd.DataFrame(data=y_ros,columns=cols2)\n",
    "    return X_ros, y_ros\n",
    "\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.RandomUnderSampler.html\n",
    "#ΠΡΟΣΕΧΕ ΜΗΝ ΧΑΣΕΙΣ ΧΡΗΣΙΜΕΣ ΠΛΗΡΟΦΟΡΙΕΣ\n",
    "#Random undersampling deletes examples from the majority class\n",
    "def randomundersampler(train,train_labels):\n",
    "    cols1=train.columns\n",
    "    cols2=train_labels.columns\n",
    "    rus = RandomUnderSampler(return_indices=True)\n",
    "    X_rus, y_rus, id_rus = rus.fit_sample(train,train_labels)\n",
    "    X_rus=pd.DataFrame(data=X_rus,columns=cols1)\n",
    "    y_rus=pd.DataFrame(data=y_rus,columns=cols2)\n",
    "    return X_rus, y_rus\n",
    "\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.TomekLinks.html\n",
    "#Works with Links\n",
    "#The procedure can be used to find all of those examples in the majority class that are closest to the minority class, then removed.\n",
    "def tomekundersampler(train,train_labels):\n",
    "    cols1=train.columns\n",
    "    cols2=train_labels.columns\n",
    "    tl = TomekLinks(return_indices=True, ratio='majority')\n",
    "    X_tl, y_tl, id_tl = tl.fit_sample(train, train_labels)\n",
    "    X_tl=pd.DataFrame(data=X_tl,columns=cols1)\n",
    "    y_t1=pd.DataFrame(data=y_tl,columns=cols2)\n",
    "    return X_tl, y_tl\n",
    "\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.combine.SMOTETomek.html\n",
    "#Resamples the dataset\n",
    "def smotomek(train,train_labels):\n",
    "    cols1=train.columns\n",
    "    cols2=train_labels.columns\n",
    "    smt = SMOTETomek(ratio='auto')\n",
    "    X_smt, y_smt = smt.fit_sample(train, train_labels)\n",
    "    X_smt=pd.DataFrame(data=X_smt,columns=cols1)\n",
    "    y_smt=pd.DataFrame(data=y_smt,columns=cols2)\n",
    "    return X_smt, y_smt\n",
    "\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.ClusterCentroids.html\n",
    "#Uses KMeans algorithm \n",
    "#UnderSamples by replacing a cluster of majority samples by the cluster centroid of a KMeans algorithm.\n",
    "def clusterunder(train,train_labels):\n",
    "    cols1=train.columns\n",
    "    cols2=train_labels.columns\n",
    "    cc = ClusterCentroids()\n",
    "    X_cc, y_cc = cc.fit_sample(train, train_labels)\n",
    "    X_cc=pd.DataFrame(data=X_cc,columns=cols1)\n",
    "    y_cc=pd.DataFrame(data=y_cc,columns=cols2)\n",
    "    return X_cc, y_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Μείωση της διαστατικότητας , πέφτουν οι διαστάσεις του σετ μας με αποτέλεσμα να έχουμε καλύτερο αποτέλεσμα\n",
    "!! Πολυ χρήσιμο όταν χρησιμοποιούμε one hot encoder !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=25 , STO EPOMENO THA DOUME PWS VRISKOYME TH VELTISTH PARAMETRO\n",
    "def pca(n,train,test):\n",
    "    pcaa = PCA(n_components=n)\n",
    "    trainPCA =  pcaa.fit_transform(train)\n",
    "    testPCA = pcaa.transform(test)\n",
    "    return trainPCA , testPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
